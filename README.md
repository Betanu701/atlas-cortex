# Atlas Cortex

A self-evolving AI assistant system built on top of [Open WebUI](https://github.com/open-webui/open-webui) and [Ollama](https://ollama.com). Atlas Cortex transforms a standard LLM chat into a **self-learning, personality-evolving home AI** that gets faster, smarter, and more human over time.

## What It Does

- **Instant answers** (~5ms) â€” date/time, math, identity questions with zero LLM overhead
- **Direct smart home control** (~100ms) â€” executes Home Assistant commands via API, no LLM round trip
- **Self-learning patterns** â€” commands that fall through to the LLM are analyzed nightly and converted into fast regex patterns
- **Sentiment-aware filler streaming** â€” starts responding immediately with contextual phrases while the LLM generates the real answer
- **Spatial awareness** â€” knows which room you're in via satellite mics, presence sensors, and speaker identity to scope commands automatically
- **Voice identification** â€” recognizes household members by voice and personalizes responses
- **Emotional evolution** â€” builds unique personality traits per user relationship over time
- **Age-appropriate responses** â€” adapts vocabulary, tone, and content filtering for toddlers, children, teens, and adults
- **Persistent memory** â€” HOT/COLD architecture with vector search, BM25, and RRF fusion for instant context recall
- **Conversational onboarding** â€” learns about users naturally through conversation, never overwrites, always builds upon
- **Animated avatar** â€” lip-synced face on satellite displays using phoneme-to-viseme mapping, emotion-driven expressions
- **Honest personality** â€” pushes back on bad ideas, challenges users in tutoring mode, never sycophantic
- **Anti-hallucination** â€” internal confidence scoring, grounding loops, mistake tracking and learning
- **Personal knowledge access** â€” indexes files, email, messages, calendar with strict user-scoped privacy

## Architecture

```
User Message (typed or voice)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Atlas Cortex Pipe           â”‚
â”‚                                     â”‚
â”‚  Layer 0: Context    (~1ms)         â”‚
â”‚    User ID, sentiment, time-of-day  â”‚
â”‚                                     â”‚
â”‚  Layer 1: Instant    (~5ms)         â”‚
â”‚    Date, math, greetings, identity  â”‚
â”‚                                     â”‚
â”‚  Layer 2: Commands   (~100ms)       â”‚
â”‚    HA device control, learned       â”‚
â”‚    patterns, direct API calls       â”‚
â”‚                                     â”‚
â”‚  Layer 3: LLM        (~500-4000ms)  â”‚
â”‚    Filler stream â†’ Ollama API       â”‚
â”‚    Auto-selects model by complexity â”‚
â”‚                                     â”‚
â”‚  Logger: every interaction saved    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼ (nightly)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Evolution Engine              â”‚
â”‚  â€¢ Discover new HA devices          â”‚
â”‚  â€¢ Learn patterns from fallthrough  â”‚
â”‚  â€¢ Evolve emotional profiles        â”‚
â”‚  â€¢ Optimize pattern database        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Hardware Target

- **Server:** Unraid (Overwatch) at 192.168.3.8
- **GPU:** AMD Radeon RX 7900 XT (20GB VRAM, RDNA3)
- **CPU:** AMD Ryzen 7 5700G (8c/16t, 128GB DDR4)
- **Models:** Qwen3 30B-A3B (thinking), Qwen2.5 14B (fast)
- **Stack:** Ollama (ROCm) + Open WebUI + SearXNG + faster-whisper + piper

## Project Structure

```
atlas-cortex/
â”œâ”€â”€ README.md                  # This file
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md        # Detailed system architecture
â”‚   â”œâ”€â”€ data-model.md          # Database schema and relationships
â”‚   â”œâ”€â”€ memory-system.md       # HOT/COLD memory with vector search
â”‚   â”œâ”€â”€ user-profiles.md       # Age-awareness, onboarding, profile evolution
â”‚   â”œâ”€â”€ personality.md         # Honesty system, pushback, tutoring mode
â”‚   â”œâ”€â”€ grounding.md           # Anti-hallucination, confidence scoring, mistake learning
â”‚   â”œâ”€â”€ knowledge-access.md    # File/email/message indexing, user-scoped privacy
â”‚   â”œâ”€â”€ avatar-system.md       # Lip-sync avatars, visemes, multi-skin
â”‚   â”œâ”€â”€ phases.md              # Implementation phases and dependencies
â”‚   â””â”€â”€ infrastructure.md      # Current server/container topology
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipe/                  # Open WebUI Pipe function (core)
â”‚   â”œâ”€â”€ memory/                # HOT/COLD memory engine
â”‚   â”œâ”€â”€ evolution/             # Nightly cron job scripts
â”‚   â””â”€â”€ speaker-id/            # Speaker identification sidecar
â”œâ”€â”€ config/
â”‚   â””â”€â”€ docker-compose.yml     # Container deployment (evolution + speaker-id)
â”œâ”€â”€ seeds/
â”‚   â””â”€â”€ command_patterns.sql   # Initial HA command patterns
â””â”€â”€ tests/
    â”œâ”€â”€ test_sentiment.py
    â”œâ”€â”€ test_patterns.py
    â”œâ”€â”€ test_memory.py
    â””â”€â”€ test_instant.py
```

## Implementation Phases

| Phase | Name | Status | Description |
|-------|------|--------|-------------|
| C1 | Core Pipe | ğŸ”² Planned | Sentiment, instant answers, HA commands, filler streaming, logging |
| C2 | Self-Learning | ğŸ”² Planned | Nightly device discovery, fallthrough analysis, pattern generation |
| C3 | Voice Identity | ğŸ”² Planned | Speaker recognition, enrollment, spatial awareness |
| C4 | Emotional Evolution | ğŸ”² Planned | Rapport tracking, personality drift, proactive suggestions |
| C5 | Memory System | ğŸ”² Planned | HOT/COLD paths, vector search, BM25, RRF fusion, ChromaDB |
| C6 | User Profiles | ğŸ”² Planned | Age-awareness, onboarding, parental controls, profile evolution |
| C7 | Avatar System | ğŸ”² Future | Phoneme-to-viseme lip-sync, emotion expressions, multi-skin |
| C8 | Knowledge Access | ğŸ”² Future | File/email/message indexing, user-scoped privacy, source connectors |

See [docs/phases.md](docs/phases.md) for detailed task breakdown and dependency graph.

## Prerequisites

- [Ollama](https://ollama.com) with ROCm (AMD GPU) or CUDA (NVIDIA)
- [Open WebUI](https://github.com/open-webui/open-webui) v0.8.5+
- [Home Assistant](https://www.home-assistant.io/) with long-lived access token
- Python 3.11+

## License

MIT
