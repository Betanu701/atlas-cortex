<div align="center">

# ğŸ§  Atlas Cortex

**A self-evolving AI assistant that learns, adapts, and grows with your household.**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/tests-285%20passing-brightgreen.svg)](#testing)
[![Open WebUI](https://img.shields.io/badge/Open%20WebUI-compatible-orange.svg)](https://github.com/open-webui/open-webui)

*Hardware-agnostic Â· Privacy-first Â· Family-safe Â· Self-learning*

</div>

---

Atlas Cortex transforms a local LLM into an intelligent home assistant that understands who's speaking, adapts to each family member, controls your smart home, and gets smarter every day â€” all running on **your hardware**, with **zero cloud dependencies**.

## âœ¨ Key Features

### ğŸš€ Intelligent Response Pipeline
| Layer | Latency | What Happens |
|-------|---------|--------------|
| **Context Assembly** | ~1ms | Identifies speaker, room, sentiment, time-of-day |
| **Instant Answers** | ~5ms | Date, time, math, greetings â€” no LLM needed |
| **Plugin Dispatch** | ~100ms | Smart home control, lists, knowledge search |
| **LLM Generation** | ~500â€“4000ms | Full reasoning with filler streaming for zero perceived wait |

### ğŸ  Smart Home Integration
- **Natural language control** â€” *"Turn off the bedroom lights"* executes directly via Home Assistant API
- **Spatial awareness** â€” knows which room you're in via satellite mics and presence sensors
- **Scene automation** â€” *"Good night"* triggers your bedtime routine
- **Self-learning** â€” commands that go to the LLM are analyzed nightly and converted into fast regex patterns

### ğŸ—£ï¸ Voice & Speech Engine
- **Emotional TTS** â€” Orpheus speech synthesis with natural pauses, breathing, laughter, and emotion tags
- **Voice identification** â€” recognizes family members by voice, personalizes responses per person
- **Multiple providers** â€” Orpheus (emotional, GPU), Piper (fast, CPU fallback), extensible provider interface
- **Sentence-boundary streaming** â€” starts speaking before the full response is generated

### ğŸ›¡ï¸ Safety & Content Policy
- **Age-appropriate responses** â€” automatically adapts vocabulary and content for toddlers, children, teens, and adults
- **Educational mode** â€” uses scientific terminology for biology/anatomy at all ages â€” never evasive
- **5-layer jailbreak defense** â€” regex patterns, semantic analysis, system prompt hardening, output monitoring, adaptive learning
- **PII protection** â€” SSN, credit card, phone, email auto-redacted from logs and memory
- **Crisis detection** â€” recognizes self-harm/emergency language and responds with appropriate resources

### ğŸ§  Memory & Learning
- **HOT/COLD architecture** â€” ChromaDB vector search + SQLite FTS5 with reciprocal rank fusion
- **Persistent memory** â€” remembers conversations, preferences, and facts across sessions
- **Nightly evolution** â€” analyzes patterns, learns from mistakes, evolves personality profiles
- **Anti-hallucination** â€” confidence scoring, grounding loops, and mistake tracking

### ğŸ‘¤ User Profiles & Personality
- **Per-user adaptation** â€” vocabulary level, preferred tone, communication style
- **Honest personality** â€” pushes back on bad ideas, challenges in tutoring mode, never sycophantic
- **Emotional evolution** â€” builds unique rapport with each household member over time
- **Parental controls** â€” content filtering, allowed hours, restricted actions per child

## ğŸ—ï¸ Architecture

```
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚    User Interface    â”‚
                          â”‚  Open WebUI / Voice  â”‚
                          â”‚  / Satellite Mics    â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚    Atlas Cortex      â”‚
                          â”‚    Server (:5100)    â”‚
                          â”‚  OpenAI-compatible   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                      â”‚                      â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Input Pipeline   â”‚ â”‚  Safety Guardrails â”‚ â”‚   Voice Engine    â”‚
    â”‚                    â”‚ â”‚                    â”‚ â”‚                   â”‚
    â”‚ L0: Context  (1ms) â”‚ â”‚ â€¢ Content tiers    â”‚ â”‚ â€¢ Orpheus TTS     â”‚
    â”‚ L1: Instant  (5ms) â”‚ â”‚ â€¢ Jailbreak defenseâ”‚ â”‚ â€¢ Piper fallback  â”‚
    â”‚ L2: Plugins (100ms)â”‚ â”‚ â€¢ PII redaction    â”‚ â”‚ â€¢ Emotion tags    â”‚
    â”‚ L3: LLM   (500ms+)â”‚ â”‚ â€¢ Crisis detection â”‚ â”‚ â€¢ Voice streaming â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    Integrations                        â”‚
    â”‚                                                       â”‚
    â”‚  ğŸ  Home Assistant   ğŸ“‹ Lists   ğŸ“š Knowledge   ğŸ” Memory  â”‚
    â”‚  ğŸ”§ Service Discovery   ğŸ“¦ Backup   ğŸ“ Learning        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  SQLite + ChromaDB   â”‚
                     â”‚  (WAL mode, 50+ tbl) â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Nightly Evolution  â”‚
                     â”‚  Pattern learning    â”‚
                     â”‚  Profile evolution   â”‚
                     â”‚  Device discovery    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Multi-GPU Support

Atlas detects all GPUs at startup and assigns optimal roles:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPU 0 (Largest)â”‚     â”‚  GPU 1 (Second) â”‚     â”‚  iGPU (Fallback)â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚     â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚     â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”‚
â”‚  LLM Inference  â”‚     â”‚  Voice / TTS    â”‚     â”‚  Lightweight    â”‚
â”‚  Ollama :11434  â”‚     â”‚  Ollama :11435  â”‚     â”‚  tasks only     â”‚
â”‚  20GB+ VRAM     â”‚     â”‚  8-12GB VRAM    â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Supported GPUs**: AMD (ROCm), NVIDIA (CUDA), Intel (oneAPI/IPEX), Apple (Metal)
- **Auto-sizing**: Models selected based on available VRAM â€” from 1.7B (4GB) to 72B (48GB+)
- **Mixed vendors**: Run AMD + Intel GPUs in the same system via separate containers

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.11+**
- **[Ollama](https://ollama.com)** â€” any GPU or CPU-only
- **[Open WebUI](https://github.com/open-webui/open-webui) v0.8.5+** (recommended) or any OpenAI-compatible client

### Quick Start (Docker)

```bash
# Clone the repository
git clone https://github.com/Betanu701/atlas-cortex.git
cd atlas-cortex

# Start with Docker Compose
docker compose -f docker/docker-compose.yml up -d

# Atlas is now running at http://localhost:5100
```

### Quick Start (Manual)

```bash
# Clone and set up
git clone https://github.com/Betanu701/atlas-cortex.git
cd atlas-cortex

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run the interactive installer
python -m cortex.install

# Or start the server directly
python -m cortex.server
```

### Connect to Open WebUI

1. Open your Open WebUI instance
2. Go to **Admin â†’ Settings â†’ Connections**
3. Add a new OpenAI-compatible connection:
   - **URL**: `http://<atlas-host>:5100/v1`
   - **Model**: `atlas-cortex`
4. Start chatting â€” Atlas handles the rest

### Discover Your Services

```bash
# Scan your network for Home Assistant, Nextcloud, MQTT, etc.
python -m cortex.discover
```

Atlas finds available services on your network and configures integrations automatically.

## âš™ï¸ Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `CORTEX_HOST` | `0.0.0.0` | Server bind address |
| `CORTEX_PORT` | `5100` | Server port |
| `CORTEX_DATA_DIR` | `./data` | Database and state directory |
| `LLM_PROVIDER` | `ollama` | LLM backend (`ollama`, `openai_compatible`) |
| `OLLAMA_BASE_URL` | `http://localhost:11434` | Ollama API URL |
| `OPENAI_BASE_URL` | â€” | Custom OpenAI-compatible endpoint |
| `OPENAI_API_KEY` | â€” | API key for OpenAI-compatible backends |
| `MODEL_FAST` | `qwen2.5:14b` | Model for quick factual answers |
| `MODEL_THINKING` | `qwen3:30b-a3b` | Model for complex reasoning |
| `HA_URL` | â€” | Home Assistant URL (e.g., `http://192.168.1.100:8123`) |
| `HA_TOKEN` | â€” | Home Assistant long-lived access token |

## ğŸ“¡ API Reference

Atlas exposes an **OpenAI-compatible API** so any client that works with OpenAI/Ollama works with Atlas.

### Chat Completions

```bash
# Streaming
curl http://localhost:5100/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "atlas-cortex",
    "messages": [{"role": "user", "content": "Turn off the living room lights"}],
    "stream": true
  }'
```

### Text-to-Speech

```bash
# Generate speech with emotion
curl http://localhost:5100/v1/audio/speech \
  -H "Content-Type: application/json" \
  -d '{
    "model": "orpheus",
    "input": "Good morning! The weather looks beautiful today.",
    "voice": "tara",
    "emotion": "happy"
  }' --output speech.wav

# List available voices
curl http://localhost:5100/v1/audio/voices
```

### Health Check

```bash
curl http://localhost:5100/health
```

## ğŸ“ Project Structure

```
atlas-cortex/
â”œâ”€â”€ cortex/                        # Core Python package
â”‚   â”œâ”€â”€ server.py                  # OpenAI-compatible FastAPI server
â”‚   â”œâ”€â”€ pipe.py                    # Open WebUI Pipe function
â”‚   â”œâ”€â”€ db.py                      # SQLite schema (50+ tables, WAL mode)
â”‚   â”œâ”€â”€ pipeline/                  # 4-layer processing pipeline
â”‚   â”‚   â”œâ”€â”€ layer0_context.py      #   Context assembly, sentiment, spatial
â”‚   â”‚   â”œâ”€â”€ layer1_instant.py      #   Instant answers (math, date, identity)
â”‚   â”‚   â”œâ”€â”€ layer2_plugins.py      #   Plugin dispatch (HA, lists, knowledge)
â”‚   â”‚   â””â”€â”€ layer3_llm.py          #   Filler streaming + LLM generation
â”‚   â”œâ”€â”€ providers/                 # LLM backend abstraction
â”‚   â”‚   â”œâ”€â”€ ollama.py              #   Ollama provider
â”‚   â”‚   â””â”€â”€ openai_compat.py       #   Any OpenAI-compatible backend
â”‚   â”œâ”€â”€ voice/                     # Voice & TTS engine
â”‚   â”‚   â”œâ”€â”€ providers/orpheus.py   #   Orpheus emotional TTS
â”‚   â”‚   â”œâ”€â”€ providers/piper.py     #   Piper CPU fallback
â”‚   â”‚   â”œâ”€â”€ composer.py            #   Emotion composition
â”‚   â”‚   â”œâ”€â”€ streaming.py           #   Sentence-boundary streaming
â”‚   â”‚   â””â”€â”€ registry.py            #   Voice registry & selection
â”‚   â”œâ”€â”€ safety/                    # Safety guardrails
â”‚   â”‚   â”œâ”€â”€ __init__.py            #   Content tiers, input/output guards
â”‚   â”‚   â””â”€â”€ jailbreak.py           #   5-layer jailbreak defense
â”‚   â”œâ”€â”€ plugins/                   # Plugin framework
â”‚   â”œâ”€â”€ integrations/              # Part 2 integrations
â”‚   â”‚   â”œâ”€â”€ ha/                    #   Home Assistant (client, bootstrap, plugin)
â”‚   â”‚   â”œâ”€â”€ knowledge/             #   Document indexing & search
â”‚   â”‚   â”œâ”€â”€ lists/                 #   Smart lists (multi-backend)
â”‚   â”‚   â””â”€â”€ learning/              #   Nightly self-learning engine
â”‚   â”œâ”€â”€ memory/                    # HOT/COLD memory architecture
â”‚   â”œâ”€â”€ profiles/                  # User profiles & age-awareness
â”‚   â”œâ”€â”€ context/                   # Context window management
â”‚   â”œâ”€â”€ filler/                    # Sentiment-aware filler streaming
â”‚   â”œâ”€â”€ grounding/                 # Anti-hallucination engine
â”‚   â”œâ”€â”€ backup/                    # Automated backup/restore
â”‚   â”œâ”€â”€ install/                   # Hardware detection & installer
â”‚   â””â”€â”€ discovery/                 # Network service discovery
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                 # Production container
â”‚   â””â”€â”€ docker-compose.yml         # Full stack deployment
â”œâ”€â”€ docs/                          # Design documentation (17 files)
â”œâ”€â”€ seeds/
â”‚   â””â”€â”€ command_patterns.sql       # Initial HA command patterns
â”œâ”€â”€ tests/                         # 285 tests
â”œâ”€â”€ requirements.txt
â””â”€â”€ pytest.ini
```

## ğŸ§ª Testing

```bash
# Run all tests
source .venv/bin/activate
python -m pytest tests/ -q

# Run specific module
python -m pytest tests/test_pipeline.py -v
python -m pytest tests/test_safety.py -v
python -m pytest tests/test_voice.py -v
```

**Current status: 285 tests passing** across pipeline, providers, safety, voice, discovery, integrations, filler, memory, and learning modules.

## ğŸ“Š Implementation Status

### Part 1: Core Engine

| Phase | Module | Status | Description |
|-------|--------|--------|-------------|
| C0 | Installer & Backend | âœ… Complete | LLM provider abstraction, GPU detection, CLI installer |
| C1 | Core Pipeline | âœ… Complete | 4-layer pipeline, sentiment, instant answers, filler streaming |
| C3a | Voice Identity | ğŸ”² Planned | Speaker recognition, enrollment, age estimation |
| C4 | Emotional Evolution | ğŸ”² Planned | Rapport tracking, personality drift, proactive suggestions |
| C5 | Memory System | ğŸ”² Planned | HOT/COLD paths, vector search, BM25, RRF fusion |
| C6 | User Profiles | ğŸ”² Planned | Age-awareness, onboarding, parental controls |
| C7 | Avatar System | ğŸ”² Planned | Phoneme-to-viseme lip-sync, emotion expressions |
| C9 | Backup & Restore | âœ… Complete | Automated nightly backups, one-command restore |
| C10 | Context & Hardware | ğŸ”² Planned | Context windows, compaction, overflow recovery |
| C11 | Voice & Speech | âœ… Complete | TTS providers (Orpheus + Piper), emotion, streaming |
| C12 | Safety Guardrails | âœ… Complete | Content tiers, jailbreak defense, PII redaction |

### Part 2: Integration Layer

| Phase | Module | Status | Description |
|-------|--------|--------|-------------|
| I1 | Service Discovery | âœ… Complete | HTTP-probe scanner, service registry, config wizard |
| I2 | Home Assistant | âœ… Complete | REST client, device bootstrap, pattern matching |
| I3 | Voice Pipeline | ğŸ”² Planned | Wyoming integration, room awareness, multi-mic |
| I4 | Self-Learning | âœ… Complete | Fallthrough analysis, pattern lifecycle, nightly evolution |
| I5 | Knowledge Sources | âœ… Complete | Document processor, FTS5 index, privacy gates |
| I6 | List Management | âœ… Complete | Multi-backend lists, permissions, natural language |
| I7 | Offsite Backup | ğŸ”² Planned | NAS sync for disaster recovery |

## ğŸ—ºï¸ Roadmap â€” Future Features

These are planned enhancements that build on the existing architecture:

### â° Alarms, Timers & Reminders
- *"Wake me up at 7am"* â€” alarm management via Home Assistant media players
- *"Set a timer for 15 minutes"* â€” cooking timers with voice notifications
- *"Remind me to take medicine at 3pm"* â€” recurring reminders with snooze
- *"Remind me when I get home to check the mail"* â€” location-aware triggers

### ğŸŒ… Routines & Automations
- *"Good morning"* â€” triggers wake-up routine: lights on, coffee maker, weather briefing, calendar summary
- *"Good night"* â€” locks doors, turns off lights, sets alarm, plays sleep sounds
- *"I'm leaving"* â€” arms security, adjusts thermostat, turns off non-essential devices
- Custom routines built conversationally: *"When I say 'movie time', dim the living room to 20% and turn on the TV"*

### ğŸ“… Calendar & Scheduling
- Reads from CalDAV/Google/Outlook calendars
- *"What's on my schedule today?"* â€” morning briefing
- *"Schedule a dentist appointment for next Thursday at 2pm"*
- Proactive reminders: *"You have a meeting in 15 minutes"*

### ğŸµ Media & Entertainment
- *"Play jazz in the living room"* â€” multi-room audio via HA media players
- *"What song is this?"* â€” audio recognition
- *"Recommend a movie for family night"* â€” preference-aware suggestions

### ğŸŒ¤ï¸ Proactive Intelligence
- Weather-aware actions: *"It's going to rain â€” should I close the garage?"*
- Energy optimization: *"You've left the AC on for 8 hours â€” the house is at 68Â°F"*
- Anomaly detection: *"The basement humidity is unusually high"*
- Package tracking: *"Your Amazon order arrives tomorrow between 2-6pm"*

### ğŸ“š Learning & Education
- Homework help with age-appropriate explanations
- Interactive quizzes: *"Quiz me on state capitals"*
- Science experiments: *"What happens if we mix baking soda and vinegar?"*
- Language learning: vocabulary drills, pronunciation practice

### ğŸ¾ Household Management
- Pet care reminders: feeding schedules, vet appointments, medication
- Cooking assistant: step-by-step recipes with integrated timers
- Inventory tracking: *"We're running low on milk"* â†’ auto-add to grocery list
- Chore assignments: fair rotation tracking for household members

### ğŸ”’ Security & Monitoring
- Camera feed summaries: *"Who was at the front door?"*
- Motion alert intelligence: distinguishes pets, packages, people
- Door/window status: *"Is the garage door open?"*
- Visitor history: *"When did the kids get home from school?"*

### ğŸŒ Multi-Language Support
- Real-time language detection and switching
- Per-user language preferences
- Translation assistance between household members

### ğŸ“¢ Intercom & Broadcasting
- *"Tell the kids dinner is ready"* â€” broadcast to specific rooms
- *"Announce: family meeting in 5 minutes"* â€” whole-house broadcast
- Room-to-room communication via satellite speakers

## ğŸ“– Documentation

Comprehensive design documentation lives in the [`docs/`](docs/) directory:

| Document | Description |
|----------|-------------|
| [Architecture](docs/architecture.md) | System design, pipeline layers, evolution engine |
| [Data Model](docs/data-model.md) | 50+ SQLite tables, normalized schema, relationships |
| [Voice Engine](docs/voice-engine.md) | TTS providers, emotion composition, streaming |
| [Safety Guardrails](docs/safety-guardrails.md) | Content tiers, jailbreak defense, crisis protocol |
| [Context Management](docs/context-management.md) | Context windows, compaction, multi-GPU detection |
| [Memory System](docs/memory-system.md) | HOT/COLD architecture, vector search, RRF fusion |
| [User Profiles](docs/user-profiles.md) | Age-awareness, onboarding, parental controls |
| [Personality](docs/personality.md) | Honesty system, pushback, tutoring mode |
| [Grounding](docs/grounding.md) | Anti-hallucination, confidence scoring |
| [Knowledge Access](docs/knowledge-access.md) | Document indexing, privacy gates |
| [Lists](docs/lists.md) | Multi-backend lists, permissions |
| [Avatar System](docs/avatar-system.md) | Lip-sync, visemes, emotion expressions |
| [Backup & Restore](docs/backup-restore.md) | Automated backups, one-command restore |
| [Installation](docs/installation.md) | Installer flow, backend abstraction |
| [Phases](docs/phases.md) | Implementation roadmap and dependency graph |

## ğŸ¤ Contributing

Atlas Cortex is open source and welcomes contributions!

1. **Fork** the repository
2. **Create a feature branch**: `git checkout -b feature/my-feature`
3. **Make your changes** and add tests
4. **Run the test suite**: `python -m pytest tests/ -q`
5. **Submit a Pull Request**

### Development Setup

```bash
git clone https://github.com/Betanu701/atlas-cortex.git
cd atlas-cortex
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
python -m pytest tests/ -q  # verify everything works
```

## ğŸ“„ License

[MIT](LICENSE) â€” use it, modify it, build on it.
