# ── Atlas Cortex Environment Configuration ───────────────────────
# Copy to .env and customize. All values shown are defaults.

# ── General ──────────────────────────────────────────────────────
TZ=America/New_York
PUID=99
PGID=100

# ── Atlas Cortex Server ──────────────────────────────────────────
CORTEX_PORT=5100
# ADMIN_USERNAME=admin
# ADMIN_PASSWORD=atlas-admin

# ── LLM Backend (Ollama) ────────────────────────────────────────
LLM_PROVIDER=ollama
LLM_URL=http://localhost:11434
# LLM_API_KEY=           # Only needed for OpenAI/Anthropic providers
MODEL_FAST=qwen2.5:7b
MODEL_THINKING=qwen3:30b-a3b
MODEL_EMBEDDING=nomic-embed-text

# Ollama container image (change for GPU support):
#   CPU:       ollama/ollama:latest
#   AMD ROCm:  ollama/ollama:rocm
OLLAMA_IMAGE=ollama/ollama:latest

# ── TTS (Piper) ─────────────────────────────────────────────────
PIPER_VOICE=en_US-lessac-medium
PIPER_LENGTH=1.0
PIPER_NOISE=0.667
PIPER_NOISEW=0.333
PIPER_SPEAKER=0
PIPER_PROCS=1

# ── STT (Faster-Whisper) ────────────────────────────────────────
WHISPER_MODEL=distil-large-v3
WHISPER_BEAM=1
WHISPER_LANG=en

# ── Orpheus TTS (optional — requires GPU) ───────────────────────
# ORPHEUS_URL=http://localhost:11434

# ── GPU Configuration ───────────────────────────────────────────
# For GPU support, use the appropriate override file:
#   AMD:    docker compose -f docker-compose.yml -f docker-compose.gpu-amd.yml up -d
#   Intel:  docker compose -f docker-compose.yml -f docker-compose.gpu-intel.yml up -d
#   NVIDIA: docker compose -f docker-compose.yml -f docker-compose.gpu-nvidia.yml up -d
